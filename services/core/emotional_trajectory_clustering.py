"""
EMOTIONAL TRAJECTORY CLUSTERING
–ö–ª–∞—Å—Ç–µ—Ä–∏–∑—É–µ—Ç —Ñ–æ—Ä–º—ã —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã—Ö –ø–µ—Ä–µ—Ö–æ–¥–æ–≤ –≤–º–µ—Å—Ç–æ —É—Å—Ä–µ–¥–Ω–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π.

Key Idea:
- –ù–ï —Å—Ä–µ–¥–Ω–µ–µ –ø–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º (–ø–ª–æ—Ö–æ - —Ä–∞–∑–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã)
- –ö–ª–∞—Å—Ç–µ—Ä—ã —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏–π (—Ö–æ—Ä–æ—à–æ - —Ñ–æ—Ä–º–∞ –ø–µ—Ä–µ—Ö–æ–¥–∞, –Ω–µ –∑–Ω–∞—á–µ–Ω–∏—è)

–¢—Ä–∞–µ–∫—Ç–æ—Ä–∏—è = (emotional_state_before ‚Üí intermediate states ‚Üí emotional_state_after)
–§–æ—Ä–º–∞ = shape of curve, –Ω–µ absolute values
"""

import uuid
from typing import List, Dict, Optional, Tuple
from datetime import datetime, timezone
from sqlalchemy import select, and_
from database import AsyncSessionLocal
from models import AffectiveMemoryEntry, Goal


class TrajectoryPoint:
    """–¢–æ—á–∫–∞ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–π —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏–∏"""
    def __init__(self, state: Dict[str, float], created_at: datetime, phase: str):
        """
        Args:
            state: {arousal, valence, focus, confidence}
            created_at: –ö–æ–≥–¥–∞ —ç—Ç–æ –±—ã–ª–æ
            phase: 'start', 'during', 'end'
        """
        self.state = state
        self.created_at = created_at  # ‚Üê –ò—Å–ø–æ–ª—å–∑—É–µ–º created_at –∫–∞–∫ –≤ –º–æ–¥–µ–ª–∏
        self.timestamp = created_at  # ‚Üê –î–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å–æ —Å—Ç–∞—Ä—ã–º –∫–æ–¥–æ–º
        self.phase = phase


class EmotionalTrajectory:
    """–≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–∞—è —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏—è - sequence of states through task lifecycle"""

    def __init__(
        self,
        trajectory_id: str,
        user_id: str,
        goal_id: Optional[str],
        action_type: str,
        outcome: str,
        points: List[TrajectoryPoint]
    ):
        self.trajectory_id = trajectory_id
        self.user_id = user_id
        self.goal_id = goal_id
        self.action_type = action_type  # 'deep_goal_decomposition', 'complex_execution', etc
        self.outcome = outcome  # 'success', 'failure', 'aborted'
        self.points = points

    def get_shape_features(self) -> Dict[str, float]:
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç –§–û–†–ú–£ —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏–∏ (–Ω–µ –∞–±—Å–æ–ª—é—Ç–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è!)

        –§–æ—Ä–º–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (shape features):
        - delta_changes: –∫–∞–∫ –∏–∑–º–µ–Ω–∏–ª–∞—Å—å –∫–∞–∂–¥–∞—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å
        - volatility: –Ω–∞—Å–∫–æ–ª—å–∫–æ —Å–∏–ª—å–Ω–æ –∫–æ–ª–µ–±–∞–ª–∞—Å—å
        - trend_direction: –æ–±—â–∏–π –≤–µ–∫—Ç–æ—Ä –∏–∑–º–µ–Ω–µ–Ω–∏—è
        - peak_deviation: –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –æ—Ç start
        """
        if len(self.points) < 2:
            return {}

        start_state = self.points[0].state
        end_state = self.points[-1].state

        # –î–µ–ª—å—Ç—ã –¥–ª—è –∫–∞–∂–¥–æ–π —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏
        deltas = {
            f"{dim}_delta": end_state.get(dim, 0.5) - start_state.get(dim, 0.5)
            for dim in ["arousal", "valence", "focus", "confidence"]
        }

        # Volatility = —Å—Ä–µ–¥–Ω–µ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ –º–µ–∂–¥—É —Å–æ—Å–µ–¥–Ω–∏–º–∏ —Ç–æ—á–∫–∞–º–∏
        if len(self.points) > 2:
            changes = []
            for i in range(1, len(self.points)):
                prev_state = self.points[i-1].state
                curr_state = self.points[i].state
                change = sum(
                    abs(curr_state.get(dim, 0.5) - prev_state.get(dim, 0.5))
                    for dim in ["arousal", "valence", "focus", "confidence"]
                )
                changes.append(change)
            volatility = sum(changes) / len(changes)
        else:
            volatility = 0.0

        # Peak deviation = –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –æ—Ç start
        peak_deviations = []
        for point in self.points[1:]:
            deviation = sum(
                abs(point.state.get(dim, 0.5) - start_state.get(dim, 0.5))
                for dim in ["arousal", "valence", "focus", "confidence"]
            )
            peak_deviations.append(deviation)
        peak_deviation = max(peak_deviations) if peak_deviations else 0.0

        # Trend direction = –≤–µ–∫—Ç–æ—Ä –∏–∑–º–µ–Ω–µ–Ω–∏–π (4D vector)
        trend_vector = [
            end_state.get(dim, 0.5) - start_state.get(dim, 0.5)
            for dim in ["arousal", "valence", "focus", "confidence"]
        ]

        return {
            **deltas,
            "volatility": volatility,
            "peak_deviation": peak_deviation,
            "trend_vector": trend_vector,
            "num_points": len(self.points),
            "duration_hours": (
                (self.points[-1].timestamp - self.points[0].timestamp).total_seconds() / 3600
                if len(self.points) >= 2 else 0.0
            )
        }


class TrajectoryExtractor:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏–∏ –∏–∑ Affective Memory"""

    async def extract_trajectories(
        self,
        user_id: Optional[str] = None,
        action_type: Optional[str] = None,
        outcome: Optional[str] = None,
        limit: int = 100
    ) -> List[EmotionalTrajectory]:
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏–∏ –∏–∑ Affective Memory

        Args:
            user_id: –§–∏–ª—å—Ç—Ä –ø–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é (None = –≤—Å–µ)
            action_type: –§–∏–ª—å—Ç—Ä –ø–æ —Ç–∏–ø—É –¥–µ–π—Å—Ç–≤–∏—è
            outcome: –§–∏–ª—å—Ç—Ä –ø–æ –∏—Å—Ö–æ–¥—É
            limit: –ú–∞–∫—Å–∏–º—É–º —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏–π
        """
        async with AsyncSessionLocal() as db:
            # –ü–æ–ª—É—á–∞–µ–º –∑–∞–ø–∏—Å–∏ –∏–∑ Affective Memory
            query = select(AffectiveMemoryEntry).order_by(
                AffectiveMemoryEntry.created_at.desc()
            )

            if user_id:
                query = query.where(AffectiveMemoryEntry.user_id == uuid.UUID(user_id))

            if limit:
                query = query.limit(limit * 2)  # –ë–µ—Ä–µ–º –±–æ–ª—å—à–µ, –æ—Ç—Ñ–∏–ª—å—Ç—Ä—É–µ–º –Ω–∏–∂–µ

            result = await db.execute(query)
            entries = result.scalars().all()

            # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ goal_id –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏–π
            # –¢—Ä–∞–µ–∫—Ç–æ—Ä–∏—è = –≤—Å–µ –∑–∞–ø–∏—Å–∏ –¥–ª—è –æ–¥–Ω–æ–π —Ü–µ–ª–∏ –≤ —Ö—Ä–æ–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–º –ø–æ—Ä—è–¥–∫–µ
            # –¢—Ä–∞–µ–∫—Ç–æ—Ä–∏—è = –≤—Å–µ –∑–∞–ø–∏—Å–∏ –¥–ª—è –æ–¥–Ω–æ–π —Ü–µ–ª–∏ –≤ —Ö—Ä–æ–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–º –ø–æ—Ä—è–¥–∫–µ
            goal_trajectories = {}  # {goal_id: [entries]}

            for entry in entries:
                goal_id = entry.goal_id
                if not goal_id:
                    continue

                if goal_id not in goal_trajectories:
                    goal_trajectories[goal_id] = []
                goal_trajectories[goal_id].append(entry)

            # –°—Ç—Ä–æ–∏–º —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏–∏
            trajectories = []

            for goal_id, goal_entries in goal_trajectories.items():
                # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ created_at
                goal_entries.sort(key=lambda e: e.created_at)

                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º action_type –ø–æ —Ü–µ–ª–∏
                action = await self._infer_action_type(db, goal_id)
                if action_type and action != action_type:
                    continue

                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º outcome
                last_entry = goal_entries[-1]
                outcome_val = last_entry.outcome
                if outcome and outcome_val != outcome:
                    continue

                # –°—Ç—Ä–æ–∏–º —Ç–æ—á–∫–∏ —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏–∏
                points = []
                for entry in goal_entries:
                    # –§–∞–∑–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è
                    if entry == goal_entries[0]:
                        phase = 'start'
                    elif entry == goal_entries[-1]:
                        phase = 'end'
                    else:
                        phase = 'during'

                    point = TrajectoryPoint(
                        state=entry.emotional_state_before,
                        created_at=entry.created_at,
                        phase=phase
                    )
                    points.append(point)

                # –°–æ–∑–¥–∞–µ–º —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏—é
                trajectory = EmotionalTrajectory(
                    trajectory_id=str(uuid.uuid4()),
                    user_id=str(goal_entries[0].user_id),
                    goal_id=str(goal_id),
                    action_type=action,
                    outcome=outcome_val,
                    points=points
                )
                trajectories.append(trajectory)

                if len(trajectories) >= limit:
                    break

            return trajectories

    async def _infer_action_type(self, db, goal_id: uuid.UUID) -> str:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–∏–ø –¥–µ–π—Å—Ç–≤–∏—è –ø–æ —Ü–µ–ª–∏"""
        try:
            stmt = select(Goal).where(Goal.id == goal_id)
            result = await db.execute(stmt)
            goal = result.scalar_one_or_none()

            if not goal:
                return "unknown"

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º action_type –ø–æ —Å–≤–æ–π—Å—Ç–≤–∞–º —Ü–µ–ª–∏
            if goal.is_atomic:
                return "simple_task"
            elif goal.depth_level >= 2:
                return "deep_goal_decomposition"
            elif goal.goal_type == "exploratory":
                return "exploration_task"
            elif goal.goal_type == "continuous":
                return "routine_task"
            else:
                return "complex_execution"

        except:
            return "unknown"


class TrajectoryCluster:
    """–ö–ª–∞—Å—Ç–µ—Ä —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã—Ö —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏–π"""

    def __init__(self, cluster_id: str, action_type: str):
        self.cluster_id = cluster_id
        self.action_type = action_type
        self.trajectories: List[EmotionalTrajectory] = []
        self.centroid_features: Optional[Dict[str, float]] = None
        self.typical_outcome: Optional[str] = None
        self.success_rate: float = 0.0

    def add_trajectory(self, trajectory: EmotionalTrajectory):
        """–î–æ–±–∞–≤–ª—è–µ—Ç —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏—é –≤ –∫–ª–∞—Å—Ç–µ—Ä"""
        self.trajectories.append(trajectory)
        self._recalculate()

    def _recalculate(self):
        """–ü–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ—Ç —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –∫–ª–∞—Å—Ç–µ—Ä–∞"""
        if not self.trajectories:
            return

        # –í—ã—á–∏—Å–ª—è–µ–º centroid (—Å—Ä–µ–¥–Ω–∏–µ shape features)
        all_features = [t.get_shape_features() for t in self.trajectories]
        all_features = [f for f in all_features if f]  # —É–±–∏—Ä–∞–µ–º –ø—É—Å—Ç—ã–µ

        if not all_features:
            return

        # –£—Å—Ä–µ–¥–Ω—è–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏
        self.centroid_features = {}
        for key in all_features[0].keys():
            if key == "trend_vector":
                # –î–ª—è –≤–µ–∫—Ç–æ—Ä–∞ —É—Å—Ä–µ–¥–Ω—è–µ–º –ø–æ–∫–æ–º–ø–æ–Ω–µ–Ω—Ç–Ω–æ
                vectors = [f[key] for f in all_features if isinstance(f[key], list)]
                if vectors:
                    self.centroid_features[key] = [
                        sum(v[i] for v in vectors) / len(vectors)
                        for i in range(len(vectors[0]))
                    ]
            elif isinstance(all_features[0][key], (int, float)):
                values = [f[key] for f in all_features if key in f]
                if values:
                    self.centroid_features[key] = sum(values) / len(values)

        # –í—ã—á–∏—Å–ª—è–µ–º —Ç–∏–ø–∏—á–Ω—ã–π –∏—Å—Ö–æ–¥
        outcomes = [t.outcome for t in self.trajectories]
        success_count = outcomes.count("success")
        self.typical_outcome = "success" if success_count > len(outcomes) / 2 else "failure"
        self.success_rate = success_count / len(outcomes) if outcomes else 0.0

    def predict_outcome(self, trajectory: EmotionalTrajectory) -> Tuple[str, float]:
        """
        –ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç –∏—Å—Ö–æ–¥ –¥–ª—è —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏–∏

        Returns:
            (predicted_outcome, confidence)
        """
        if not self.trajectories:
            return "unknown", 0.0

        # Confidence = —Ä–∞–∑–º–µ—Ä –∫–ª–∞—Å—Ç–µ—Ä–∞ (—á–µ–º –±–æ–ª—å—à–µ, —Ç–µ–º —É–≤–µ—Ä–µ–Ω–Ω–µ–µ)
        confidence = min(len(self.trajectories) / 10.0, 1.0)  # –Ω–æ—Ä–º–∏—Ä—É–µ–º –¥–æ 1.0

        return self.typical_outcome, confidence


class TrajectoryClusterer:
    """–ö–ª–∞—Å—Ç–µ—Ä–∏–∑—É–µ—Ç —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏–∏"""

    def __init__(self, num_clusters: int = 5):
        """
        Args:
            num_clusters: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ action_type
        """
        self.num_clusters = num_clusters
        self.extractor = TrajectoryExtractor()
        self.clusters: Dict[str, List[TrajectoryCluster]] = {}  # {action_type: [clusters]}

    async def build_clusters(self, user_id: Optional[str] = None):
        """
        –°—Ç—Ä–æ–∏—Ç –∫–ª–∞—Å—Ç–µ—Ä—ã –∏–∑ Affective Memory

        Args:
            user_id: –ï—Å–ª–∏ —É–∫–∞–∑–∞–Ω, —Å—Ç—Ä–æ–∏—Ç –∫–ª–∞—Å—Ç–µ—Ä—ã —Ç–æ–ª—å–∫–æ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        """
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –≤—Å–µ —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏–∏
        all_trajectories = await self.extractor.extract_trajectories(
            user_id=user_id,
            limit=1000
        )

        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ action_type
        trajectories_by_action = {}
        for traj in all_trajectories:
            action = traj.action_type
            if action not in trajectories_by_action:
                trajectories_by_action[action] = []
            trajectories_by_action[action].append(traj)

        # –ö–ª–∞—Å—Ç–µ—Ä–∏–∑—É–µ–º –∫–∞–∂–¥—É—é –≥—Ä—É–ø–ø—É –æ—Ç–¥–µ–ª—å–Ω–æ
        self.clusters = {}

        for action_type, trajectories in trajectories_by_action.items():
            if not trajectories:
                continue

            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ—Å—Ç–æ–π K-means –ø–æ shape features
            action_clusters = await self._kmeans_clustering(
                trajectories,
                self.num_clusters
            )

            self.clusters[action_type] = action_clusters

            print(f"üìä Built {len(action_clusters)} clusters for action '{action_type}'")

    async def _kmeans_clustering(
        self,
        trajectories: List[EmotionalTrajectory],
        k: int
    ) -> List[TrajectoryCluster]:
        """–ü—Ä–æ—Å—Ç–æ–π K-means –ø–æ shape features"""

        if len(trajectories) < k:
            # –ï—Å–ª–∏ —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏–π –º–∞–ª–æ, —Å–æ–∑–¥–∞–µ–º –ø–æ –æ–¥–Ω–æ–π –Ω–∞ –∫–ª–∞—Å—Ç–µ—Ä
            k = max(1, len(trajectories))

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è: –≤—ã–±–∏—Ä–∞–µ–º k —Å–ª—É—á–∞–π–Ω—ã—Ö —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏–π –∫–∞–∫ —Ü–µ–Ω—Ç—Ä–æ–∏–¥—ã
        import random
        initial_indices = random.sample(range(len(trajectories)), k)
        initial_centroids = [
            trajectories[i].get_shape_features()
            for i in initial_indices
        ]

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–ª–∞—Å—Ç–µ—Ä—ã
        clusters = [
            TrajectoryCluster(
                cluster_id=f"{trajectories[initial_indices[i]].action_type}_cluster_{i}",
                action_type=trajectories[0].action_type
            )
            for i in range(k)
        ]

        # K-means –∏—Ç–µ—Ä–∞—Ü–∏–∏
        max_iterations = 10
        for iteration in range(max_iterations):
            # –û—á–∏—â–∞–µ–º –∫–ª–∞—Å—Ç–µ—Ä—ã
            for cluster in clusters:
                cluster.trajectories = []

            # –†–∞—Å–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏–∏ –ø–æ –±–ª–∏–∂–∞–π—à–∏–º —Ü–µ–Ω—Ç—Ä–æ–∏–¥–∞–º
            for traj in trajectories:
                features = traj.get_shape_features()
                if not features:
                    continue

                # –ù–∞—Ö–æ–¥–∏–º –±–ª–∏–∂–∞–π—à–∏–π –∫–ª–∞—Å—Ç–µ—Ä
                best_cluster_idx = self._find_nearest_cluster(features, initial_centroids)
                clusters[best_cluster_idx].add_trajectory(traj)

            # –ü–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ–º —Ü–µ–Ω—Ç—Ä–æ–∏–¥—ã
            new_centroids = [
                cluster.centroid_features
                for cluster in clusters
            ]

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ö–æ–¥–∏–º–æ—Å—Ç—å
            if self._centroids_converged(initial_centroids, new_centroids):
                break

            initial_centroids = new_centroids

        return clusters

    def _find_nearest_cluster(
        self,
        features: Dict[str, float],
        centroids: List[Dict[str, float]]
    ) -> int:
        """–ù–∞—Ö–æ–¥–∏—Ç –±–ª–∏–∂–∞–π—à–∏–π —Ü–µ–Ω—Ç—Ä–æ–∏–¥"""

        min_distance = float('inf')
        best_idx = 0

        for idx, centroid in enumerate(centroids):
            if not centroid:
                continue

            distance = self._compute_distance(features, centroid)
            if distance < min_distance:
                min_distance = distance
                best_idx = idx

        return best_idx

    def _compute_distance(
        self,
        features1: Dict[str, float],
        features2: Dict[str, float]
    ) -> float:
        """–í—ã—á–∏—Å–ª—è–µ—Ç —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –º–µ–∂–¥—É –¥–≤—É–º—è sets of features"""

        # –ï–≤–∫–ª–∏–¥–æ–≤–æ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –ø–æ —á–∏—Å–ª–æ–≤—ã–º –ø—Ä–∏–∑–Ω–∞–∫–∞–º
        distance = 0.0
        count = 0

        for key in features1:
            if key == "trend_vector":
                # –î–ª—è –≤–µ–∫—Ç–æ—Ä–æ–≤ –≤—ã—á–∏—Å–ª—è–µ–º –æ—Ç–¥–µ–ª—å–Ω–æ
                vec1 = features1.get(key, [0, 0, 0, 0])
                vec2 = features2.get(key, [0, 0, 0, 0])
                if isinstance(vec1, list) and isinstance(vec2, list):
                    vec_distance = sum(
                        (vec1[i] - vec2[i]) ** 2
                        for i in range(min(len(vec1), len(vec2)))
                    )
                    distance += vec_distance
                    count += 1
            elif isinstance(features1[key], (int, float)) and isinstance(features2.get(key), (int, float)):
                distance += (features1[key] - features2[key]) ** 2
                count += 1

        if count == 0:
            return float('inf')

        return distance ** 0.5  # sqrt

    def _centroids_converged(
        self,
        old_centroids: List[Dict[str, float]],
        new_centroids: List[Dict[str, float]],
        threshold: float = 0.01
    ) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å—Ö–æ–¥–∏–º–æ—Å—Ç—å —Ü–µ–Ω—Ç—Ä–æ–∏–¥–æ–≤"""

        for old, new in zip(old_centroids, new_centroids):
            if not old or not new:
                return False

            distance = self._compute_distance(old, new)
            if distance > threshold:
                return False

        return True

    def find_similar_trajectories(
        self,
        trajectory: EmotionalTrajectory,
        top_k: int = 5
    ) -> List[Tuple[EmotionalTrajectory, float]]:
        """
        –ù–∞—Ö–æ–¥–∏—Ç –ø–æ—Ö–æ–∂–∏–µ —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏–∏

        Returns:
            List of (trajectory, similarity_score)
        """
        # –ò—â–µ–º –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–º –∫–ª–∞—Å—Ç–µ—Ä–µ
        action_type = trajectory.action_type
        if action_type not in self.clusters:
            return []

        # –ù–∞—Ö–æ–¥–∏–º –±–ª–∏–∂–∞–π—à–∏–π –∫–ª–∞—Å—Ç–µ—Ä
        features = trajectory.get_shape_features()
        if not features:
            return []

        best_cluster = None
        min_distance = float('inf')

        for cluster in self.clusters[action_type]:
            if cluster.centroid_features:
                distance = self._compute_distance(features, cluster.centroid_features)
                if distance < min_distance:
                    min_distance = distance
                    best_cluster = cluster

        if not best_cluster:
            return []

        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º top-k —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏–π –∏–∑ –∫–ª–∞—Å—Ç–µ—Ä–∞
        similarities = []
        for traj in best_cluster.trajectories:
            traj_features = traj.get_shape_features()
            if traj_features:
                distance = self._compute_distance(features, traj_features)
                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º distance –≤ similarity (1 / (1 + distance))
                similarity = 1.0 / (1.0 + distance)
                similarities.append((traj, similarity))

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ similarity
        similarities.sort(key=lambda x: x[1], reverse=True)
        return similarities[:top_k]

    def predict_trajectory_outcome(
        self,
        trajectory: EmotionalTrajectory
    ) -> Tuple[str, float, Dict[str, float]]:
        """
        –ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç –∏—Å—Ö–æ–¥ —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤

        Returns:
            (predicted_outcome, confidence, expected_delta)
        """
        # –ù–∞—Ö–æ–¥–∏–º –ø–æ—Ö–æ–∂–∏–µ —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏–∏
        similar_trajectories = self.find_similar_trajectories(trajectory, top_k=10)

        if not similar_trajectories:
            return "unknown", 0.0, {}

        # –ê–≥—Ä–µ–≥–∏—Ä—É–µ–º –∏—Å—Ö–æ–¥—ã
        total_weight = 0.0
        success_weight = 0.0
        expected_deltas = {
            "arousal": 0.0,
            "valence": 0.0,
            "focus": 0.0,
            "confidence": 0.0
        }

        for traj, similarity in similar_trajectories:
            weight = similarity
            total_weight += weight

            if traj.outcome == "success":
                success_weight += weight

            # –í—ã—á–∏—Å–ª—è–µ–º delta –¥–ª—è —ç—Ç–æ–π —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏–∏
            if len(traj.points) >= 2:
                start_state = traj.points[0].state
                end_state = traj.points[-1].state

                for dim in expected_deltas:
                    delta = end_state.get(dim, 0.5) - start_state.get(dim, 0.5)
                    expected_deltas[dim] += delta * weight

        # –ù–æ—Ä–º–∏—Ä—É–µ–º
        if total_weight > 0:
            success_rate = success_weight / total_weight
            predicted_outcome = "success" if success_rate > 0.5 else "failure"
            confidence = abs(success_rate - 0.5) * 2.0  # 0 –ø—Ä–∏ 0.5, 1 –ø—Ä–∏ 0/1

            for dim in expected_deltas:
                expected_deltas[dim] /= total_weight
        else:
            predicted_outcome = "unknown"
            confidence = 0.0

        return predicted_outcome, confidence, expected_deltas


# =============================================================================
# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä
# =============================================================================

trajectory_clusterer = TrajectoryClusterer(num_clusters=5)
