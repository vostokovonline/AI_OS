"""
Emotional Inference Engine v2 (EIE v2)
=====================================

–ü–æ–ª–Ω–æ—Ü–µ–Ω–Ω–∞—è –ø–æ–¥—Å–∏—Å—Ç–µ–º–∞ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è, —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∏ –æ–±—É—á–µ–Ω–∏—è
—ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã—Ö —Å–æ—Å—Ç–æ—è–Ω–∏–π –≤ AI-OS.

–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ (5 —Å–ª–æ—ë–≤):
1. State Reconstruction Engine ‚Äî –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ —Ä–µ–∞–ª—å–Ω–æ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è
2. Pattern Context Builder ‚Äî –∞–Ω–∞–ª–∏–∑ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
3. Emotional Forecasting Engine ‚Äî –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –ø–æ—Å–ª–µ–¥—Å—Ç–≤–∏–π
4. Intent Alignment Layer ‚Äî —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–∏–µ —Å –Ω–∞–º–µ—Ä–µ–Ω–∏—è–º–∏
5. Decision Modifiers + Safeguards ‚Äî –≤—ã—Ö–æ–¥–Ω—ã–µ –º–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã

–ö–ª—é—á–µ–≤—ã–µ –æ—Ç–ª–∏—á–∏—è –æ—Ç v1:
- –í—Ä–µ–º–µ–Ω–Ω–∞—è –¥–∏–Ω–∞–º–∏–∫–∞ (time-decay, recovery)
- Meta-outcomes (learning gain, unexpected)
- Emotional forecasting (simulation)
- Intent alignment (restore/maintain/progress)
- Safeguards (collapse protection)
"""

from typing import Dict, List, Optional, Tuple, Literal
from datetime import datetime, timedelta, timezone
from dataclasses import dataclass, field
from sqlalchemy import select, and_, func, case
from database import AsyncSessionLocal
from models import (
    EmotionalLayerState,
    AffectiveMemoryEntry,
    Goal,
    EmotionalForecast  # üÜï STEP 2.4
)
from emotional_config import EMOTIONAL_BASELINE
import math


# =============================================================================
# DATA STRUCTURES
# =============================================================================

@dataclass
class EmotionalState:
    """–†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è"""
    arousal: float       # 0..1, baseline 0.5
    valence: float       # -1..1, baseline 0.0
    focus: float         # 0..1, baseline 0.5
    confidence: float    # 0..1, baseline 0.5
    timestamp: datetime = None

    def to_dict(self) -> Dict:
        return {
            "arousal": self.arousal,
            "valence": self.valence,
            "focus": self.focus,
            "confidence": self.confidence,
            "timestamp": self.timestamp.isoformat() if self.timestamp else None,
        }

    @classmethod
    def from_dict(cls, data: Dict) -> "EmotionalState":
        return cls(
            arousal=data.get("arousal", 0.5),
            valence=data.get("valence", 0.0),
            focus=data.get("focus", 0.5),
            confidence=data.get("confidence", 0.5),
            timestamp=datetime.fromisoformat(data["timestamp"]) if data.get("timestamp") else datetime.now(timezone.utc),
        )


@dataclass
class MetaOutcome:
    """–ú–µ—Ç–∞-—Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è (learning-aware)"""
    outcome: Literal["success", "failure", "aborted"]
    learning_gain: float = 0.0      # 0..1, –Ω–∞—Å–∫–æ–ª—å–∫–æ –º—ã –Ω–∞—É—á–∏–ª–∏—Å—å
    unexpected: bool = False        # –±—ã–ª –ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–º
    effort: float = 0.5             # 0..1, —Å–∫–æ–ª—å–∫–æ —É—Å–∏–ª–∏–π –ø–æ—Ç—Ä–∞—á–µ–Ω–æ
    user_reflection: str = ""       # —Ä–µ—Ñ–ª–µ–∫—Å–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è


@dataclass
class EmotionalTransition:
    """–≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π –ø–µ—Ä–µ—Ö–æ–¥ (–µ–¥–∏–Ω–∏—Ü–∞ –æ–±—É—á–µ–Ω–∏—è)"""
    before: EmotionalState
    after: EmotionalState
    meta_outcome: MetaOutcome
    context: Dict = field(default_factory=dict)  # goal_type, complexity, etc.

    def delta(self) -> Dict[str, float]:
        """–í—ã—á–∏—Å–ª–∏—Ç—å –∏–∑–º–µ–Ω–µ–Ω–∏–µ —ç–º–æ—Ü–∏–π"""
        return {
            "arousal": self.after.arousal - self.before.arousal,
            "valence": self.after.valence - self.before.valence,
            "focus": self.after.focus - self.before.focus,
            "confidence": self.after.confidence - self.before.confidence,
        }


@dataclass
class EmotionalIntent:
    """–≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–µ –Ω–∞–º–µ—Ä–µ–Ω–∏–µ (—á–µ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Ö–æ—á–µ—Ç —á—É–≤—Å—Ç–≤–æ–≤–∞—Ç—å)"""
    primary: Literal[
        "restore_confidence",
        "reduce_arousal",
        "maintain_focus",
        "increase_engagement",
        "neutral"
    ]
    priority: float = 0.5  # 0..1


@dataclass
class EmotionalForecast:
    """–ü—Ä–æ–≥–Ω–æ–∑ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è"""
    predicted_state: EmotionalState
    risk_flags: List[str] = field(default_factory=list)
    expected_delta: Dict[str, float] = field(default_factory=dict)
    confidence: float = 0.5  # 0..1, —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ –ø—Ä–æ–≥–Ω–æ–∑–µ
    # üÜï STEP 2.4: Forecast persistence
    forecast_id: Optional[str] = None  # UUID –∏–∑ EmotionalForecast (DB model)
    used_tier: Optional[str] = None  # "ML" | "Clusters" | "Rules"


@dataclass
class PatternContext:
    """–ö–æ–Ω—Ç–µ–∫—Å—Ç —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
    risk_profile: Dict[str, float] = field(default_factory=dict)
    dominant_patterns: List[str] = field(default_factory=list)
    success_correlations: Dict[str, float] = field(default_factory=dict)


# =============================================================================
# LAYER 1: State Reconstruction Engine
# =============================================================================

class StateReconstructionEngine:
    """
    –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç —Ä–µ–∞–ª—å–Ω–æ–µ —Ç–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Å —É—á—ë—Ç–æ–º –≤—Ä–µ–º–µ–Ω–∏ –∏ –ø–µ—Ä–µ—Ö–æ–¥–æ–≤.
    """

    # Time-decay constants (hours to decay to 37%)
    DECAY_RATES = {
        "arousal": 2.0,      # –±—ã—Å—Ç—Ä–æ –ø–∞–¥–∞–µ—Ç
        "valence": 12.0,     # –º–µ–¥–ª–µ–Ω–Ω–æ –º–µ–Ω—è–µ—Ç—Å—è
        "focus": 6.0,        # —Å—Ä–µ–¥–Ω—è—è —Å–∫–æ—Ä–æ—Å—Ç—å
        "confidence": 24.0,  # –æ—á–µ–Ω—å –º–µ–¥–ª–µ–Ω–Ω–æ —Ä–∞—Å—Ç—ë—Ç/–ø–∞–¥–∞–µ—Ç
    }

    def decay_state(self, state: EmotionalState, dt_hours: float) -> EmotionalState:
        """
        –ü—Ä–∏–º–µ–Ω–∏—Ç—å —ç–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–µ –∑–∞—Ç—É—Ö–∞–Ω–∏–µ –∫ —Å–æ—Å—Ç–æ—è–Ω–∏—é.

        Formula: value = baseline + (current - baseline) * exp(-dt / half_life)
        """
        decayed = EmotionalState(
            arousal=self._decay_dimension(state.arousal, 0.5, dt_hours, self.DECAY_RATES["arousal"]),
            valence=self._decay_dimension(state.valence, 0.0, dt_hours, self.DECAY_RATES["valence"]),
            focus=self._decay_dimension(state.focus, 0.5, dt_hours, self.DECAY_RATES["focus"]),
            confidence=self._decay_dimension(state.confidence, 0.5, dt_hours, self.DECAY_RATES["confidence"]),
            timestamp=datetime.now(timezone.utc),
        )
        return decayed

    def _decay_dimension(self, value: float, baseline: float, dt_hours: float, half_life: float) -> float:
        """–ó–∞—Ç—É—Ö–∞–Ω–∏–µ –æ–¥–Ω–æ–π —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ –∫ baseline"""
        delta = value - baseline
        decay_factor = math.exp(-dt_hours / half_life)
        return baseline + delta * decay_factor

    async def reconstruct_state(self, user_id: str) -> EmotionalState:
        """
        –í–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —Ä–µ–∞–ª—å–Ω–æ–µ —Ç–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.

        –ê–ª–≥–æ—Ä–∏—Ç–º:
        1. –í–∑—è—Ç—å –ø–æ—Å–ª–µ–¥–Ω–µ–µ –∑–∞–ø–∏—Å–∞–Ω–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ
        2. –ü—Ä–∏–º–µ–Ω–∏—Ç—å time-decay
        3. –£—á–µ—Å—Ç—å –Ω–µ–¥–∞–≤–Ω–∏–µ –ø–µ—Ä–µ—Ö–æ–¥—ã
        """
        async with AsyncSessionLocal() as db:
            # 1. Get last recorded state
            stmt = select(EmotionalLayerState).where(
                EmotionalLayerState.user_id == user_id
            ).order_by(
                EmotionalLayerState.created_at.desc()
            ).limit(1)

            result = await db.execute(stmt)
            last_db_state = result.scalar_one_or_none()

            if not last_db_state:
                # No history - return baseline
                return EmotionalState(
                    arousal=0.5, valence=0.0, focus=0.5, confidence=0.5,
                    timestamp=datetime.now(timezone.utc)
                )

            # Convert to EmotionalState
            last_state = EmotionalState(
                arousal=last_db_state.arousal,
                valence=last_db_state.valence,
                focus=last_db_state.focus,
                confidence=last_db_state.confidence,
                timestamp=last_db_state.created_at,
            )

            # 2. Apply time-decay
            dt_hours = (datetime.now(timezone.utc) - last_state.timestamp).total_seconds() / 3600
            decayed_state = self.decay_state(last_state, dt_hours)

            # 3. Apply recent transitions (if any)
            # Get last 5 transitions from affective memory
            stmt_trans = select(AffectiveMemoryEntry).where(
                AffectiveMemoryEntry.user_id == user_id
            ).order_by(
                AffectiveMemoryEntry.created_at.desc()
            ).limit(5)

            result_trans = await db.execute(stmt_trans)
            transitions = result_trans.scalars().all()

            # Apply recent transition effects (with decay based on age)
            for trans in transitions:
                trans_dt = (datetime.now(timezone.utc) - trans.created_at).total_seconds() / 3600
                if trans_dt < 1.0:  # Only apply very recent transitions (< 1 hour)
                    trans_weight = math.exp(-trans_dt)  # Recent = more weight
                    after_state = trans.emotional_state_after or {}

                    # Blend current state with transition state
                    decayed_state.arousal = (
                        decayed_state.arousal * (1 - trans_weight * 0.1) +
                        after_state.get("arousal", 0.5) * trans_weight * 0.1
                    )
                    decayed_state.valence = (
                        decayed_state.valence * (1 - trans_weight * 0.1) +
                        after_state.get("valence", 0.0) * trans_weight * 0.1
                    )

            return decayed_state


# =============================================================================
# LAYER 2: Pattern Context Builder
# =============================================================================

class PatternContextBuilder:
    """
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.
    """

    async def build_context(self, user_id: str, limit: int = 100) -> PatternContext:
        """
        –ü–æ—Å—Ç—Ä–æ–∏—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –∏–∑ Affective Memory.

        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
        - risk_profile: —Ä–∏—Å–∫–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏—Å—Ç–æ—Ä–∏–∏
        - dominant_patterns: –æ—Å–Ω–æ–≤–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
        - success_correlations: –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ —Å —É—Å–ø–µ—Ö–æ–º
        """
        async with AsyncSessionLocal() as db:
            # Get transitions from affective memory
            stmt = select(AffectiveMemoryEntry).where(
                AffectiveMemoryEntry.user_id == user_id
            ).order_by(
                AffectiveMemoryEntry.created_at.desc()
            ).limit(limit)

            result = await db.execute(stmt)
            memories = result.scalars().all()

            if not memories:
                return PatternContext()

            # Analyze patterns
            transitions = self._build_transitions(memories)
            risk_profile = self._analyze_risks(transitions)
            dominant_patterns = self._extract_patterns(transitions)
            success_correlations = self._correlate_with_success(transitions)

            return PatternContext(
                risk_profile=risk_profile,
                dominant_patterns=dominant_patterns,
                success_correlations=success_correlations,
            )

    def _build_transitions(self, memories: List[AffectiveMemoryEntry]) -> List[EmotionalTransition]:
        """–ü–æ—Å—Ç—Ä–æ–∏—Ç—å —Å–ø–∏—Å–æ–∫ –ø–µ—Ä–µ—Ö–æ–¥–æ–≤ –∏–∑ –ø–∞–º—è—Ç–∏"""
        transitions = []
        for mem in memories:
            before = mem.emotional_state_before or {}
            after = mem.emotional_state_after or {}

            trans = EmotionalTransition(
                before=EmotionalState(
                    arousal=before.get("arousal", 0.5),
                    valence=before.get("valence", 0.0),
                    focus=before.get("focus", 0.5),
                    confidence=before.get("confidence", 0.5),
                ),
                after=EmotionalState(
                    arousal=after.get("arousal", 0.5),
                    valence=after.get("valence", 0.0),
                    focus=after.get("focus", 0.5),
                    confidence=after.get("confidence", 0.5),
                ),
                meta_outcome=MetaOutcome(
                    outcome=mem.outcome,
                    learning_gain=mem.outcome_metrics.get("learning_gain", 0.0) if mem.outcome_metrics else 0.0,
                    unexpected=mem.outcome_metrics.get("unexpected", False) if mem.outcome_metrics else False,
                ),
            )
            transitions.append(trans)

        return transitions

    def _analyze_risks(self, transitions: List[EmotionalTransition]) -> Dict[str, float]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ä–∏—Å–∫–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏—Å—Ç–æ—Ä–∏–∏"""
        risks = {}

        if not transitions:
            return risks

        # High arousal failure rate
        high_arousal_failures = [
            t for t in transitions
            if t.before.arousal > 0.7 and t.meta_outcome.outcome == "failure"
        ]
        high_arousal_total = [
            t for t in transitions
            if t.before.arousal > 0.7
        ]

        if high_arousal_total:
            risks["high_arousal_failure_rate"] = len(high_arousal_failures) / len(high_arousal_total)

        # Confidence collapse risk
        confidence_drops = [
            t for t in transitions
            if t.delta()["confidence"] < -0.2
        ]

        if transitions:
            risks["confidence_collapse_rate"] = len(confidence_drops) / len(transitions)

        # Low focus failure rate
        low_focus_failures = [
            t for t in transitions
            if t.before.focus < 0.4 and t.meta_outcome.outcome == "failure"
        ]
        low_focus_total = [
            t for t in transitions
            if t.before.focus < 0.4
        ]

        if low_focus_total:
            risks["low_focus_failure_rate"] = len(low_focus_failures) / len(low_focus_total)

        return risks

    def _extract_patterns(self, transitions: List[EmotionalTransition]) -> List[str]:
        """–ò–∑–≤–ª–µ—á—å –æ—Å–Ω–æ–≤–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã"""
        patterns = []

        if not transitions:
            return patterns

        # Success after arousal drop
        arousal_drop_success = [
            t for t in transitions
            if t.delta()["arousal"] < -0.1 and t.meta_outcome.outcome == "success"
        ]
        if len(arousal_drop_success) > len(transitions) * 0.3:
            patterns.append("success_after_arousal_drop")

        # Failure when focus < 0.4
        focus_fail = [
            t for t in transitions
            if t.before.focus < 0.4 and t.meta_outcome.outcome == "failure"
        ]
        if len(focus_fail) > len(transitions) * 0.3:
            patterns.append("failure_when_focus_low")

        # Confidence recovery after success
        conf_recovery = [
            t for t in transitions
            if t.delta()["confidence"] > 0.1 and t.meta_outcome.outcome == "success"
        ]
        if len(conf_recovery) > len(transitions) * 0.3:
            patterns.append("confidence_builds_on_success")

        return patterns

    def _correlate_with_success(self, transitions: List[EmotionalTransition]) -> Dict[str, float]:
        """–ö–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã—Ö —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–µ–π —Å —É—Å–ø–µ—Ö–æ–º"""
        if not transitions:
            return {}

        correlations = {}

        # Success rate by focus level
        high_focus_success = [
            t for t in transitions
            if t.before.focus > 0.6 and t.meta_outcome.outcome == "success"
        ]
        high_focus_total = [
            t for t in transitions
            if t.before.focus > 0.6
        ]

        if high_focus_total:
            correlations["high_focus_success_rate"] = len(high_focus_success) / len(high_focus_total)

        # Success rate by valence
        positive_valence_success = [
            t for t in transitions
            if t.before.valence > 0.2 and t.meta_outcome.outcome == "success"
        ]
        positive_valence_total = [
            t for t in transitions
            if t.before.valence > 0.2
        ]

        if positive_valence_total:
            correlations["positive_valence_success_rate"] = len(positive_valence_success) / len(positive_valence_total)

        return correlations


# =============================================================================
# LAYER 3: Emotional Forecasting Engine
# =============================================================================

class EmotionalForecastingEngine:
    """
    –ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –ø–æ—Å–ª–µ–¥—Å—Ç–≤–∏—è —Ä–µ—à–µ–Ω–∏–π.
    """

    # Action impact coefficients
    ACTION_IMPACTS = {
        "deep_goal_decomposition": {
            "arousal": 0.15,
            "valence": -0.05,
            "focus": -0.1,
            "confidence": -0.1,
        },
        "simple_task": {
            "arousal": -0.05,
            "valence": 0.05,
            "focus": 0.1,
            "confidence": 0.05,
        },
        "complex_execution": {
            "arousal": 0.2,
            "valence": -0.1,
            "focus": 0.05,
            "confidence": -0.15,
        },
        "learning_task": {
            "arousal": 0.05,
            "valence": 0.0,
            "focus": 0.1,
            "confidence": 0.02,
        },
    }

    def simulate(
        self,
        current_state: EmotionalState,
        action: str,
        pattern_context: PatternContext,
        meta_outcome: Optional[MetaOutcome] = None,
        user_id: Optional[str] = None,
        goal_id: Optional[str] = None  # üÜï STEP 2.4: optional goal_id
    ) -> EmotionalForecast:
        """
        –°–∏–º—É–ª–∏—Ä–æ–≤–∞—Ç—å —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –ø–æ—Å–ª–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –¥–µ–π—Å—Ç–≤–∏—è.

        THREE-TIER FORECASTING (–≤ –ø–æ—Ä—è–¥–∫–µ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞):
        1. ü§ñ ML Model (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–∞ –∏ —É–≤–µ—Ä–µ–Ω–∞)
        2. üìä Trajectory Clustering (–µ—Å–ª–∏ –µ—Å—Ç—å –∫–ª–∞—Å—Ç–µ—Ä—ã)
        3. üìê Rule-based (–≤—Å–µ–≥–¥–∞ –∫–∞–∫ safety net)

        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—Ä–æ–≥–Ω–æ–∑ —Å —Ä–∏—Å–∫–∞–º–∏.
        """
        # üÜï TIER 1: ML-based forecasting
        ml_impact = {}
        ml_confidence = 0.0

        try:
            from emotional_forecasting_model import emotional_forecasting_model

            if emotional_forecasting_model.is_available():
                current_dict = {
                    "arousal": current_state.arousal,
                    "valence": current_state.valence,
                    "focus": current_state.focus,
                    "confidence": current_state.confidence
                }

                pattern_dict = {
                    "risk_profile": pattern_context.risk_profile,
                    "success_correlations": pattern_context.success_correlations,
                    "dominant_patterns": pattern_context.dominant_patterns
                }

                ml_deltas, ml_conf = emotional_forecasting_model.predict(
                    current_dict, action, pattern_dict
                )

                # üÜï STEP 2.3: CONFIDENCE CALIBRATION
                # –ö–∞–ª–∏–±—Ä—É–µ–º confidence –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–æ–π —Ç–æ—á–Ω–æ—Å—Ç–∏
                try:
                    from confidence_calibrator import confidence_calibrator
                    from tier_reliability import tier_reliability_tracker

                    # –ü–æ–ª—É—á–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏ –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏ –¥–ª—è —ç—Ç–æ–≥–æ action_type
                    metrics = tier_reliability_tracker.get_reliability(action, "ML")

                    # –ö–∞–ª–∏–±—Ä—É–µ–º confidence
                    calibrated_ml_conf = confidence_calibrator.adjust(
                        raw_confidence=ml_conf,
                        action_type=action,
                        tier="ML",
                        metrics=metrics
                    )

                    print(f"üéØ [ML Calibration] {ml_conf:.3f} ‚Üí {calibrated_ml_conf:.3f}")

                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ç–∫–∞–ª–∏–±—Ä–æ–≤–∞–Ω–Ω—ã–π confidence
                    ml_conf = calibrated_ml_conf
                except Exception as calib_err:
                    print(f"‚ö†Ô∏è  [ML Calibration] Failed: {calib_err}, using raw confidence")

                # üÜï PER-ACTION CONFIDENCE: Check threshold for this action
                from ml_guardrails import per_action_confidence
                action_threshold = per_action_confidence.get_threshold(action)

                if ml_conf >= action_threshold:  # –ò—Å–ø–æ–ª—å–∑—É–µ–º ML —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —É–≤–µ—Ä–µ–Ω–∞
                    ml_impact = ml_deltas
                    ml_confidence = ml_conf
                    print(f"ü§ñ [ML Model] Using ML forecast (confidence={ml_conf:.2f}, threshold={action_threshold:.2f})")
                else:
                    print(f"‚ö†Ô∏è  [ML Model] Low confidence ({ml_conf:.2f} < {action_threshold:.2f}), trying next tier")
            else:
                print(f"‚ÑπÔ∏è  [ML Model] Not available, trying next tier")

        except Exception as e:
            print(f"‚ö†Ô∏è  [ML Model] Error: {e}, trying next tier")

        # üÜï TIER 2: Trajectory-based forecasting (–µ—Å–ª–∏ ML –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª)
        cluster_impact = {}
        cluster_confidence = 0.0
        cluster_outcome = "unknown"

        if not ml_impact:
            try:
                from emotional_trajectory_clustering import (
                    trajectory_clusterer,
                    EmotionalTrajectory,
                    TrajectoryPoint
                )

                # –°–æ–∑–¥–∞–µ–º —Ç–µ–∫—É—â—É—é —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏—é (–ø–æ–∫–∞ —Ç–æ–ª—å–∫–æ start —Ç–æ—á–∫–∞)
                current_trajectory = EmotionalTrajectory(
                    trajectory_id="temp",
                    user_id=user_id or "unknown",
                    goal_id=None,
                    action_type=action,
                    outcome="unknown",
                    points=[
                        TrajectoryPoint(
                            state={
                                "arousal": current_state.arousal,
                                "valence": current_state.valence,
                                "focus": current_state.focus,
                                "confidence": current_state.confidence
                            },
                            created_at=datetime.now(timezone.utc),
                            phase="start"
                        )
                    ]
                )

                # –ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ–º –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤
                cluster_outcome, cluster_confidence, cluster_deltas = (
                    trajectory_clusterer.predict_trajectory_outcome(current_trajectory)
                )

                if cluster_confidence > 0.3:  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–ª–∞—Å—Ç–µ—Ä—ã —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —É–≤–µ—Ä–µ–Ω—ã
                    cluster_impact = cluster_deltas
                    print(f"üìä [Trajectory Clustering] Using cluster-based forecast (confidence={cluster_confidence:.2f})")
                else:
                    print(f"‚ö†Ô∏è  [Trajectory Clustering] Low confidence, falling back to rules")

            except Exception as e:
                print(f"‚ö†Ô∏è  [Trajectory Clustering] Error: {e}, using rule-based")

        # üÜï TIER 3: Rule-based forecasting (SAFETY NET - –≤—Å–µ–≥–¥–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç)
        base_impact = self.ACTION_IMPACTS.get(action, {})
        adjusted_impact = self._adjust_for_patterns(base_impact, pattern_context)

        # üÜï –°–º–µ—à–∏–≤–∞–µ–º –≤—Å–µ —Ç—Ä–∏ –ø–æ–¥—Ö–æ–¥–∞
        final_impact = {}
        used_tiers = []

        if ml_impact and ml_confidence > 0.0:  # –£–∂–µ –ø—Ä–æ–≤–µ—Ä–µ–Ω–æ –≤ predict() —Å per-action threshold
            # ML + rules (ML primary, rules safety net)
            weight = ml_confidence  # 0.3-1.0 (varies by action)
            for dim in ["arousal", "valence", "focus", "confidence"]:
                ml_value = ml_impact.get(dim, 0)
                rule_value = adjusted_impact.get(dim, 0)
                final_impact[dim] = (1 - weight) * rule_value + weight * ml_value

            used_tiers.append("ML")
            used_tiers.append("Rules (safety net)")
            print(f"üîÄ [Mixed Forecast] ML + Rules (weight={weight:.2f})")

        elif cluster_impact and cluster_confidence > 0.3:
            # Clusters + rules
            weight = cluster_confidence  # 0.3-1.0
            for dim in ["arousal", "valence", "focus", "confidence"]:
                cluster_value = cluster_impact.get(dim, 0)
                rule_value = adjusted_impact.get(dim, 0)
                final_impact[dim] = (1 - weight) * rule_value + weight * cluster_value

            used_tiers.append("Clusters")
            used_tiers.append("Rules (safety net)")
            print(f"üîÄ [Mixed Forecast] Clusters + Rules (weight={weight:.2f})")

        else:
            # Rules only
            final_impact = adjusted_impact
            used_tiers.append("Rules only")

        print(f"üìä [Forecast Tiers] {' ‚Üí '.join(used_tiers)}")

        # Predict new state
        predicted = EmotionalState(
            arousal=self._clamp(current_state.arousal + final_impact.get("arousal", 0), 0, 1),
            valence=self._clamp(current_state.valence + final_impact.get("valence", 0), -1, 1),
            focus=self._clamp(current_state.focus + final_impact.get("focus", 0), 0, 1),
            confidence=self._clamp(current_state.confidence + final_impact.get("confidence", 0), 0, 1),
            timestamp=datetime.now(timezone.utc),
        )

        # Calculate risk flags
        risk_flags = self._detect_risks(current_state, predicted, pattern_context)

        # üÜï –ï—Å–ª–∏ —Å–∏—Å—Ç–µ–º–∞ –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç failure - –¥–æ–±–∞–≤–ª—è–µ–º —Ä–∏—Å–∫
        if cluster_outcome == "failure" and cluster_confidence > 0.6:
            risk_flags.append(f"cluster_predicted_failure (conf={cluster_confidence:.2f})")

        # Calculate expected delta
        expected_delta = {
            "arousal": predicted.arousal - current_state.arousal,
            "valence": predicted.valence - current_state.valence,
            "focus": predicted.focus - current_state.focus,
            "confidence": predicted.confidence - current_state.confidence,
        }

        # üÜï Confidence score (max –∏–∑ –≤—Å–µ—Ö tiers)
        confidences = [ml_confidence, cluster_confidence, 0.5]
        final_confidence = max([c for c in confidences if c > 0])

        # üÜï STEP 2.4: –°–æ—Ö—Ä–∞–Ω—è–µ–º forecast –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
        forecast_id, used_tier = self._save_forecast_to_db(
            user_id=user_id,
            action=action,
            expected_delta=expected_delta,
            final_confidence=final_confidence,
            used_tiers=used_tiers,
            risk_flags=risk_flags,
            goal_id=goal_id  # üÜï
        )

        return EmotionalForecast(
            predicted_state=predicted,
            risk_flags=risk_flags,
            expected_delta=expected_delta,
            confidence=final_confidence,
            forecast_id=forecast_id,  # üÜï
            used_tier=used_tier,       # üÜï
        )

    def _adjust_for_patterns(self, base_impact: Dict, context: PatternContext) -> Dict:
        """–°–∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∞—Ç—å –≤–ª–∏—è–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤"""
        adjusted = base_impact.copy()

        # If user has pattern "success_after_arousal_drop", reduce arousal penalty
        if "success_after_arousal_drop" in context.dominant_patterns:
            adjusted["arousal"] = adjusted.get("arousal", 0) * 0.8

        # If user has pattern "failure_when_focus_low", amplify focus impact
        if "failure_when_focus_low" in context.dominant_patterns:
            adjusted["focus"] = adjusted.get("focus", 0) * 1.2

        # Adjust based on risk profile
        if context.risk_profile.get("high_arousal_failure_rate", 0) > 0.7:
            adjusted["arousal"] = adjusted.get("arousal", 0) * 1.3  # More conservative

        return adjusted

    def _detect_risks(
        self,
        before: EmotionalState,
        after: EmotionalState,
        context: PatternContext
    ) -> List[str]:
        """–û–±–Ω–∞—Ä—É–∂–∏—Ç—å —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ —Ä–∏—Å–∫–∏"""
        risks = []

        # Confidence collapse
        if after.confidence < 0.3:
            risks.append("confidence_collapse")

        # Task abandonment risk
        if after.arousal > 0.85:
            risks.append("task_abandonment")

        # Burnout risk
        if before.arousal > 0.7 and after.arousal > 0.75:
            risks.append("burnout_risk")

        # Focus fragmentation
        if after.focus < 0.3:
            risks.append("focus_fragmentation")

        # Learning block
        if before.valence < -0.4 and after.valence < -0.5:
            risks.append("learning_block")

        return risks

    def _clamp(self, value: float, min_val: float, max_val: float) -> float:
        """–û–≥—Ä–∞–Ω–∏—á–∏—Ç—å –∑–Ω–∞—á–µ–Ω–∏–µ –¥–∏–∞–ø–∞–∑–æ–Ω–æ–º"""
        return max(min_val, min(max_val, value))

    def _save_forecast_to_db(
        self,
        user_id: Optional[str],
        action: str,
        expected_delta: Dict[str, float],
        final_confidence: float,
        used_tiers: List[str],
        risk_flags: List[str],
        goal_id: Optional[str] = None  # üÜï STEP 2.4: optional goal_id
    ) -> Tuple[Optional[str], str]:
        """
        üÜï STEP 2.4: –°–æ—Ö—Ä–∞–Ω—è–µ—Ç emotional forecast –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö.

        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
            (forecast_id, used_tier)
        """
        if not user_id:
            # –ë–µ–∑ user_id –Ω–µ —Å–æ—Ö—Ä–∞–Ω—è–µ–º (–≤–æ–∑–≤—Ä–∞—â–∞–µ–º None)
            return None, "Rules"

        try:
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π used_tier
            if "ML" in used_tiers:
                used_tier = "ML"
            elif "Clusters" in used_tiers:
                used_tier = "Clusters"
            else:
                used_tier = "Rules"

            # –°–æ–∑–¥–∞—ë–º –∑–∞–ø–∏—Å—å –≤ DB
            import uuid
            forecast_record = EmotionalForecast(
                id=uuid.uuid4(),
                user_id=uuid.UUID(user_id) if isinstance(user_id, str) else user_id,
                goal_id=uuid.UUID(goal_id) if goal_id else None,  # üÜï –°–æ—Ö—Ä–∞–Ω—è–µ–º goal_id
                action_type=action,
                predicted_deltas=expected_delta,  # {arousal, valence, focus, confidence}
                forecast_confidence=final_confidence,
                used_tier=used_tier,
                risk_flags=risk_flags if risk_flags else None
            )

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ DB (sync operation)
            from database import get_db
            db = next(get_db())

            try:
                db.add(forecast_record)
                db.commit()
                db.refresh(forecast_record)

                forecast_id = str(forecast_record.id)

                # üÜï –ï—Å–ª–∏ –µ—Å—Ç—å goal_id, –æ–±–Ω–æ–≤–ª—è–µ–º goal.forecast_id
                if goal_id:
                    try:
                        from models import Goal
                        goal = db.query(Goal).filter(Goal.id == uuid.UUID(goal_id)).first()
                        if goal:
                            goal.forecast_id = forecast_record.id
                            db.commit()
                            print(f"üîó [Forecast Persistence] Linked forecast {forecast_id} to goal {goal_id}")
                    except Exception as goal_err:
                        print(f"‚ö†Ô∏è  [Forecast Persistence] Failed to link to goal: {goal_err}")

                print(f"üíæ [Forecast Persistence] Saved forecast {forecast_id} (tier={used_tier}, conf={final_confidence:.2f})")

                return forecast_id, used_tier

            finally:
                db.close()

        except Exception as e:
            print(f"‚ö†Ô∏è  [Forecast Persistence] Failed to save forecast: {e}")
            import traceback
            traceback.print_exc()

            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º None, –Ω–æ –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º —Ä–∞–±–æ—Ç—É
            return None, "Rules"  # Fallback


# =============================================================================
# LAYER 4: Intent Alignment Layer
# =============================================================================

class IntentAlignmentLayer:
    """
    –°–æ–≥–ª–∞—Å—É–µ—Ç —Ä–µ—à–µ–Ω–∏—è —Å —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–º–∏ –Ω–∞–º–µ—Ä–µ–Ω–∏—è–º–∏.
    """

    def align(
        self,
        forecast: EmotionalForecast,
        intent: EmotionalIntent,
        current_state: EmotionalState
    ) -> Tuple[bool, str]:
        """
        –ü—Ä–æ–≤–µ—Ä–∏—Ç—å, —Å–æ–≥–ª–∞—Å—É–µ—Ç—Å—è –ª–∏ –ø—Ä–æ–≥–Ω–æ–∑ —Å –Ω–∞–º–µ—Ä–µ–Ω–∏–µ–º.

        Returns:
            (aligned, reason)
        """
        # If intent is neutral, always aligned
        if intent.primary == "neutral":
            return True, "neutral intent"

        # Restore confidence
        if intent.primary == "restore_confidence":
            if forecast.predicted_state.confidence < current_state.confidence:
                return False, "would reduce confidence further"
            if forecast.predicted_state.confidence < 0.4:
                return False, "confidence too low to build"
            return True, "supports confidence restoration"

        # Reduce arousal
        if intent.primary == "reduce_arousal":
            if forecast.predicted_state.arousal > current_state.arousal:
                return False, "would increase arousal"
            return True, "supports arousal reduction"

        # Maintain focus
        if intent.primary == "maintain_focus":
            if forecast.predicted_state.focus < current_state.focus - 0.1:
                return False, "would significantly reduce focus"
            return True, "maintains focus"

        # Increase engagement
        if intent.primary == "increase_engagement":
            if forecast.predicted_state.arousal < 0.3:
                return False, "too passive for engagement"
            if "task_abandonment" in forecast.risk_flags:
                return False, "high abandonment risk"
            return True, "supports engagement"

        return True, "aligned"


# =============================================================================
# LAYER 5: Decision Modifiers + Safeguards
# =============================================================================

@dataclass
class DecisionModifiers:
    """–í—ã—Ö–æ–¥–Ω—ã–µ –º–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã —Ä–µ—à–µ–Ω–∏–π"""
    max_depth: int = 3
    pace: Literal["slow", "normal", "fast"] = "normal"
    explanation_level: Literal["minimal", "normal", "detailed"] = "normal"
    style: Literal["direct", "supportive", "collaborative"] = "direct"
    safety_override: bool = False
    recovery_mode: bool = False


class DecisionModifiersEngine:
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –º–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã —Ä–µ—à–µ–Ω–∏–π —Å –∑–∞—â–∏—Ç–∞–º–∏.
    """

    # Safeguard thresholds
    SAFEGUARDS = {
        "confidence_min": 0.2,      # Below this: no complex tasks
        "arousal_max": 0.85,        # Above this: no irreversible decisions
        "focus_min": 0.25,          # Below this: simplify
        "repeated_failure_threshold": 3,  # 3+ failures in a row: recovery mode
    }

    def generate(
        self,
        forecast: EmotionalForecast,
        intent: EmotionalIntent,
        aligned: bool
    ) -> DecisionModifiers:
        """
        –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –º–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–æ–≥–Ω–æ–∑–∞ –∏ –Ω–∞–º–µ—Ä–µ–Ω–∏—è.
        """
        state = forecast.predicted_state

        # Default modifiers
        modifiers = DecisionModifiers()

        # Adjust based on forecast
        if state.confidence < 0.4:
            modifiers.max_depth = 2
            modifiers.explanation_level = "detailed"
            modifiers.style = "supportive"

        if state.confidence < 0.25:
            modifiers.max_depth = 1
            modifiers.pace = "slow"
            modifiers.style = "supportive"

        if state.arousal > 0.7:
            modifiers.max_depth = max(1, modifiers.max_depth - 1)
            modifiers.pace = "slow"
            modifiers.explanation_level = "detailed"

        if state.focus < 0.4:
            modifiers.max_depth = max(1, modifiers.max_depth - 1)
            modifiers.explanation_level = "detailed"

        if state.valence < -0.3:
            modifiers.style = "supportive"
            modifiers.pace = "slow"

        # Intent-based adjustments
        if intent.primary == "restore_confidence":
            modifiers.max_depth = min(modifiers.max_depth, 2)
            modifiers.style = "supportive"

        if intent.primary == "reduce_arousal":
            modifiers.max_depth = min(modifiers.max_depth, 2)
            modifiers.pace = "slow"

        # Apply safeguards
        modifiers = self._apply_safeguards(modifiers, forecast, aligned)

        return modifiers

    def _apply_safeguards(
        self,
        modifiers: DecisionModifiers,
        forecast: EmotionalForecast,
        aligned: bool
    ) -> DecisionModifiers:
        """–ü—Ä–∏–º–µ–Ω–∏—Ç—å –∑–∞—â–∏—Ç–Ω—ã–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è"""
        state = forecast.predicted_state

        # Confidence safeguard
        if state.confidence < self.SAFEGUARDS["confidence_min"]:
            modifiers.max_depth = 1
            modifiers.safety_override = True
            modifiers.recovery_mode = True

        # Arousal safeguard
        if state.arousal > self.SAFEGUARDS["arousal_max"]:
            modifiers.max_depth = 1
            modifiers.safety_override = True

        # Focus safeguard
        if state.focus < self.SAFEGUARDS["focus_min"]:
            modifiers.max_depth = 1
            modifiers.explanation_level = "detailed"

        # Risk flag safeguards
        if "confidence_collapse" in forecast.risk_flags:
            modifiers.recovery_mode = True
            modifiers.safety_override = True

        if "task_abandonment" in forecast.risk_flags:
            modifiers.max_depth = 1
            modifiers.safety_override = True

        # Intent misalignment
        if not aligned:
            modifiers.safety_override = True
            modifiers.max_depth = min(modifiers.max_depth, 2)

        return modifiers


# =============================================================================
# MAIN ENGINE: Emotional Inference Engine v2
# =============================================================================

class EmotionalInferenceEngineV2:
    """
    –ì–ª–∞–≤–Ω–∞—è —Ç–æ—á–∫–∞ –≤—Ö–æ–¥–∞ EIE v2.

    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –≤—Å–µ 5 —Å–ª–æ—ë–≤ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã—Ö –º–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–≤.
    """

    def __init__(self):
        self.state_reconstructor = StateReconstructionEngine()
        self.pattern_builder = PatternContextBuilder()
        self.forecaster = EmotionalForecastingEngine()
        self.intent_aligner = IntentAlignmentLayer()
        self.modifiers_engine = DecisionModifiersEngine()

    async def infer(
        self,
        user_id: str,
        proposed_action: str,
        intent: Optional[EmotionalIntent] = None,
        signals: Optional[Dict] = None,
        goal_id: Optional[str] = None  # üÜï STEP 2.4: optional goal_id
    ) -> DecisionModifiers:
        """
        –ì–ª–∞–≤–Ω–∞—è —Ç–æ—á–∫–∞ –≤—Ö–æ–¥–∞.

        –í—ã–ø–æ–ª–Ω—è–µ—Ç –ø–æ–ª–Ω—ã–π pipeline EIE v2:
        1. Reconstruct state
        2. Build pattern context
        3. Forecast emotional outcome
        4. Check intent alignment
        5. Generate decision modifiers
        """
        # Default intent
        if intent is None:
            intent = EmotionalIntent(primary="neutral")

        # 1. Reconstruct current state
        current_state = await self.state_reconstructor.reconstruct_state(user_id)

        # 2. Build pattern context
        pattern_context = await self.pattern_builder.build_context(user_id)

        # 3. Forecast emotional outcome (—Å trajectory clustering)
        forecast = self.forecaster.simulate(
            current_state=current_state,
            action=proposed_action,
            pattern_context=pattern_context,
            user_id=user_id,
            goal_id=goal_id  # üÜï STEP 2.4: –ü–µ—Ä–µ–¥–∞–µ–º goal_id
        )

        # 4. Check intent alignment
        aligned, reason = self.intent_aligner.align(
            forecast=forecast,
            intent=intent,
            current_state=current_state
        )

        if not aligned:
            print(f"‚ö†Ô∏è  Intent misalignment: {reason}")

        # 5. Generate decision modifiers
        modifiers = self.modifiers_engine.generate(
            forecast=forecast,
            intent=intent,
            aligned=aligned
        )

        # Log for debugging
        print(f"üß† [EIE v2] Inference for user {user_id}:")
        print(f"   Current state: arousal={current_state.arousal:.2f}, valence={current_state.valence:.2f}")
        print(f"   Forecast: {forecast.predicted_state.arousal:.2f}, {forecast.predicted_state.valence:.2f}")
        print(f"   Risks: {forecast.risk_flags}")
        print(f"   Modifiers: max_depth={modifiers.max_depth}, pace={modifiers.pace}")
        if modifiers.safety_override:
            print(f"   üîí SAFETY OVERRIDE ACTIVE")

        return modifiers


# =============================================================================
# SINGLETON INSTANCE
# =============================================================================

emotional_inference_engine_v2 = EmotionalInferenceEngineV2()
