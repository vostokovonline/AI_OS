"""
ML GUARDRAILS - Safety mechanisms for ML-based emotional forecasting

–¶–µ–ª—å: –ù–µ –¥–∞—Ç—å ML —Ç–∏—Ö–æ –¥–µ–≥—Ä–∞–¥–∏—Ä–æ–≤–∞—Ç—å —Å–∏—Å—Ç–µ–º—É.

–ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã:
1. Training Quality Gates - –ø—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –ø–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è
2. Per-Action Confidence - —Ä–∞–∑–Ω—ã–µ thresholds –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –¥–µ–π—Å—Ç–≤–∏–π
3. Drift Detection - –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ —Å–¥–≤–∏–≥–∞ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è
4. Forecast Error Tracking - –∑–∞–ø–∏—Å—å –∏ –∞–Ω–∞–ª–∏–∑ –æ—à–∏–±–æ–∫
"""

import uuid
import json
import numpy as np
from typing import List, Dict, Optional, Tuple, Literal
from datetime import datetime, timezone
from pathlib import Path
from sqlalchemy import select, and_
from database import AsyncSessionLocal
from models import AffectiveMemoryEntry, EmotionalLayerState

# =============================================================================
# TRAINING QUALITY GATES
# =============================================================================

class TrainingQualityGates:
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ –ø–µ—Ä–µ–¥ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ–º.

    –ï—Å–ª–∏ –º–æ–¥–µ–ª—å –Ω–µ –ø—Ä–æ—Ö–æ–¥–∏—Ç gate ‚Üí –æ–Ω–∞ –Ω–µ –ø–æ–º–µ—á–∞–µ—Ç—Å—è –∫–∞–∫ available.
    """

    # Thresholds –¥–ª—è –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–∏
    QUALITY_THRESHOLDS = {
        "min_r2_score": 0.4,          # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π R¬≤ (–æ–±—ä—è—Å–Ω–µ–Ω–Ω–∞—è –¥–∏—Å–ø–µ—Ä—Å–∏—è)
        "max_mse": 0.05,              # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è MSE (—Å—Ä–µ–¥–Ω–µ–∫–≤–∞–¥—Ä–∞—Ç–∏—á–Ω–∞—è –æ—à–∏–±–∫–∞)
        "min_samples": 30,            # –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ training samples
        "max_train_test_gap": 0.2,    # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑—Ä—ã–≤ –º–µ–∂–¥—É train/test R¬≤
    }

    @classmethod
    def evaluate_training_result(
        cls,
        metrics: Dict[str, float],
        training_samples: int
    ) -> Tuple[bool, List[str]]:
        """
        –û—Ü–µ–Ω–∏–≤–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –æ–±—É—á–µ–Ω–∏—è.

        Args:
            metrics: {'mse': 0.023, 'r2': 0.67, 'test_r2': 0.62}
            training_samples: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ training samples

        Returns:
            (passed, reasons)
            - passed: True –µ—Å–ª–∏ –º–æ–¥–µ–ª—å –ø—Ä–æ—à–ª–∞ –≤—Å–µ gates
            - reasons: –°–ø–∏—Å–æ–∫ –ø—Ä–∏—á–∏–Ω –µ—Å–ª–∏ –Ω–µ –ø—Ä–æ—à–ª–∞
        """
        reasons = []

        # Gate 1: –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ samples
        if training_samples < cls.QUALITY_THRESHOLDS["min_samples"]:
            reasons.append(
                f"Insufficient data: {training_samples} samples "
                f"(minimum {cls.QUALITY_THRESHOLDS['min_samples']} required)"
            )

        # Gate 2: –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π R¬≤
        r2_score = metrics.get("r2", 0.0)
        if r2_score < cls.QUALITY_THRESHOLDS["min_r2_score"]:
            reasons.append(
                f"Low R¬≤ score: {r2_score:.3f} "
                f"(minimum {cls.QUALITY_THRESHOLDS['min_r2_score']} required)"
            )

        # Gate 3: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è MSE
        mse = metrics.get("mse", 1.0)
        if mse > cls.QUALITY_THRESHOLDS["max_mse"]:
            reasons.append(
                f"High MSE: {mse:.4f} "
                f"(maximum {cls.QUALITY_THRESHOLDS['max_mse']} allowed)"
            )

        # Gate 4: Train/Test gap (overfitting detection)
        train_r2 = metrics.get("train_r2", r2_score)
        test_r2 = metrics.get("test_r2", r2_score)
        gap = abs(train_r2 - test_r2)

        if gap > cls.QUALITY_THRESHOLDS["max_train_test_gap"]:
            reasons.append(
                f"Overfitting detected: train/test R¬≤ gap = {gap:.3f} "
                f"(maximum {cls.QUALITY_THRESHOLDS['max_train_test_gap']} allowed)"
            )

        passed = len(reasons) == 0

        return passed, reasons

    @classmethod
    def format_quality_report(
        cls,
        metrics: Dict[str, float],
        training_samples: int,
        passed: bool,
        reasons: List[str]
    ) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —á–∏—Ç–∞–µ–º—ã–π –æ—Ç—á–µ—Ç –æ –∫–∞—á–µ—Å—Ç–≤–µ."""
        report = []
        report.append("=" * 60)
        report.append("üõ° ML TRAINING QUALITY REPORT")
        report.append("=" * 60)

        # Status
        status = "‚úÖ PASSED" if passed else "‚ùå FAILED"
        report.append(f"\nStatus: {status}")
        report.append(f"Training samples: {training_samples}")

        # Metrics
        report.append("\nüìä Metrics:")
        report.append(f"  R¬≤ Score:      {metrics.get('r2', 0.0):.4f}")
        report.append(f"  MSE:           {metrics.get('mse', 0.0):.4f}")
        if 'train_r2' in metrics:
            report.append(f"  Train R¬≤:      {metrics.get('train_r2', 0.0):.4f}")
        if 'test_r2' in metrics:
            report.append(f"  Test R¬≤:       {metrics.get('test_r2', 0.0):.4f}")

        # Thresholds
        report.append("\nüéØ Thresholds:")
        for key, value in cls.QUALITY_THRESHOLDS.items():
            report.append(f"  {key}: {value}")

        # Failure reasons
        if not passed:
            report.append("\n‚ùå Failure Reasons:")
            for reason in reasons:
                report.append(f"  ‚Ä¢ {reason}")

        report.append("\n" + "=" * 60)

        return "\n".join(report)


# =============================================================================
# PER-ACTION CONFIDENCE
# =============================================================================

class PerActionConfidence:
    """
    –†–∞–∑–Ω—ã–µ confidence thresholds –¥–ª—è —Ä–∞–∑–Ω—ã—Ö action types.

    –õ–æ–≥–∏–∫–∞:
    - routine_task ‚Üí ML –º–æ–∂–µ—Ç –±—ã—Ç—å —É–≤–µ—Ä–µ–Ω (low threshold)
    - complex_execution ‚Üí ML –º–µ–Ω–µ–µ —É–≤–µ—Ä–µ–Ω (high threshold)
    - deep_goal_decomposition ‚Üí —Å—Ä–µ–¥–Ω–∏–π threshold
    """

    ACTION_CONFIDENCE_THRESHOLDS = {
        # –ü—Ä–æ—Å—Ç—ã–µ –∑–∞–¥–∞—á–∏ ‚Üí ML —É–≤–µ—Ä–µ–Ω
        "simple_task": 0.3,
        "routine_task": 0.3,

        # –°—Ä–µ–¥–Ω—è—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å
        "learning_task": 0.4,
        "creative_task": 0.4,

        # –°–ª–æ–∂–Ω—ã–µ –∑–∞–¥–∞—á–∏ ‚Üí ML –º–µ–Ω–µ–µ —É–≤–µ—Ä–µ–Ω
        "deep_goal_decomposition": 0.5,
        "complex_execution": 0.5,

        # Default (fallback)
        "default": 0.4
    }

    @classmethod
    def get_threshold(cls, action_type: str) -> float:
        """–ü–æ–ª—É—á–∏—Ç—å confidence threshold –¥–ª—è action."""
        return cls.ACTION_CONFIDENCE_THRESHOLDS.get(
            action_type,
            cls.ACTION_CONFIDENCE_THRESHOLDS["default"]
        )

    @classmethod
    def should_use_ml(
        cls,
        action_type: str,
        ml_confidence: float
    ) -> bool:
        """
        –†–µ—à–∏—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–∏ ML –¥–ª—è —ç—Ç–æ–≥–æ action.

        Args:
            action_type: –¢–∏–ø –¥–µ–π—Å—Ç–≤–∏—è
            ml_confidence: Confidence –æ—Ç ML –º–æ–¥–µ–ª–∏

        Returns:
            True –µ—Å–ª–∏ ML –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —É–≤–µ—Ä–µ–Ω –¥–ª—è —ç—Ç–æ–≥–æ action
        """
        threshold = cls.get_threshold(action_type)
        return ml_confidence >= threshold


# =============================================================================
# DRIFT DETECTION
# =============================================================================

class DriftDetector:
    """
    –û–±–Ω–∞—Ä—É–∂–∏–≤–∞–µ—Ç —Å–¥–≤–∏–≥ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è features (drift).

    –õ–æ–≥–∏–∫–∞:
    1. –ü—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º distribution stats (mean, std)
    2. –ü—Ä–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–∏ —Å—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Ç–µ–∫—É—â–∏–µ features —Å training stats
    3. –ï—Å–ª–∏ —Å–∏–ª—å–Ω–æ –æ—Ç–ª–∏—á–∞–µ—Ç—Å—è ‚Üí drift detected ‚Üí –æ—Ç–∫–ª—é—á–∞–µ–º ML
    """

    DRIFT_THRESHOLD = 3.0  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ sigma –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ drift
    DRIFT_FEATURES_TO_CHECK = [
        "arousal", "valence", "focus", "confidence"  # Current state features
    ]

    def __init__(self):
        self.training_stats: Optional[Dict] = None  # –°–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏
        self.drift_history: List[Dict] = []

    def save_training_distribution(self, X_train: np.ndarray):
        """
        –°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É training distribution.

        Args:
            X_train: Training features matrix (n_samples, n_features)
        """
        self.training_stats = {
            "mean": np.mean(X_train, axis=0).tolist(),
            "std": np.std(X_train, axis=0).tolist(),
            "min": np.min(X_train, axis=0).tolist(),
            "max": np.max(X_train, axis=0).tolist(),
            "n_features": X_train.shape[1],
            "saved_at": datetime.now(timezone.utc).isoformat()
        }

        print(f"üìä [Drift Detection] Saved training distribution stats "
              f"({X_train.shape[0]} samples, {X_train.shape[1]} features)")

    def detect_drift(
        self,
        features: np.ndarray,
        feature_names: List[str]
    ) -> Tuple[bool, List[str]]:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –µ—Å—Ç—å –ª–∏ drift –≤ features.

        Args:
            features: –¢–µ–∫—É—â–∏–π feature vector (1D –∏–ª–∏ 2D)
            feature_names: –ò–º–µ–Ω–∞ features

        Returns:
            (drift_detected, drift_details)
        """
        if self.training_stats is None:
            return False, ["No training stats available"]

        # Convert to 2D if needed
        if len(features.shape) == 1:
            features = features.reshape(1, -1)

        drift_detected = False
        drift_details = []

        training_mean = np.array(self.training_stats["mean"])
        training_std = np.array(self.training_stats["std"])

        # Check each feature
        for i, fname in enumerate(feature_names):
            # Only check important features
            if not any(protected in fname for protected in self.DRIFT_FEATURES_TO_CHECK):
                continue

            current_val = features[0, i]
            train_mean = training_mean[i]
            train_std = training_std[i]

            if train_std < 1e-6:
                continue  # Skip constant features

            # Z-score: –Ω–∞—Å–∫–æ–ª—å–∫–æ –¥–∞–ª–µ–∫–æ –æ—Ç training mean
            z_score = abs(current_val - train_mean) / train_std

            if z_score > self.DRIFT_THRESHOLD:
                drift_detected = True
                drift_details.append(
                    f"{fname}: z={z_score:.2f} (val={current_val:.3f}, "
                    f"train_mean={train_mean:.3f} ¬± {train_std:.3f})"
                )

        if drift_detected:
            # Log to history
            self.drift_history.append({
                "timestamp": datetime.now(timezone.utc).isoformat(),
                "drift_details": drift_details,
                "features": features[0].tolist()
            })

            print(f"‚ö†Ô∏è  [Drift Detection] Drift detected!")
            for detail in drift_details:
                print(f"    ‚Ä¢ {detail}")

        return drift_detected, drift_details

    def get_drift_summary(self) -> Dict:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç summary drift history."""
        if not self.drift_history:
            return {
                "total_drifts": 0,
                "recent_drifts": []
            }

        return {
            "total_drifts": len(self.drift_history),
            "recent_drifts": self.drift_history[-10:],  # Last 10
            "training_stats": self.training_stats
        }


# =============================================================================
# FORECAST ERROR TRACKING
# =============================================================================

class ForecastErrorTracker:
    """
    –û—Ç—Å–ª–µ–∂–∏–≤–∞–µ—Ç –æ—à–∏–±–∫–∏ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª—è:
    - Quality monitoring
    - Confidence calibration
    - Retraining decisions
    """

    def __init__(self):
        self.error_history: List[Dict] = []
        self.max_history = 1000  # –•—Ä–∞–Ω–∏–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 1000 –æ—à–∏–±–æ–∫

    def record_forecast(
        self,
        user_id: str,
        action_type: str,
        predicted_deltas: Dict[str, float],
        actual_deltas: Dict[str, float],
        ml_confidence: float,
        used_tier: str  # "ML", "Clusters", "Rules"
    ):
        """
        –ó–∞–ø–∏—Å—ã–≤–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è.

        Args:
            user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            action_type: –¢–∏–ø –¥–µ–π—Å—Ç–≤–∏—è
            predicted_deltas: –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –¥–µ–ª—å—Ç—ã
            actual_deltas: –§–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –¥–µ–ª—å—Ç—ã
            ml_confidence: Confidence –æ—Ç ML (–µ—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª—Å—è)
            used_tier: –ö–∞–∫–æ–π tier –±—ã–ª –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω
        """
        # –í—ã—á–∏—Å–ª—è–µ–º –æ—à–∏–±–∫–∏
        errors = {}
        for dim in ["arousal", "valence", "focus", "confidence"]:
            pred = predicted_deltas.get(dim, 0.0)
            actual = actual_deltas.get(dim, 0.0)
            errors[dim] = {
                "absolute_error": abs(pred - actual),
                "squared_error": (pred - actual) ** 2,
                "direction_correct": (pred > 0) == (actual > 0)  # –ü—Ä–∞–≤–∏–ª—å–Ω–æ –ª–∏ —É–≥–∞–¥–∞–ª–∏ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ
            }

        # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º
        record = {
            "timestamp": datetime.now(timezone.utc).isoformat(),
            "user_id": user_id,
            "action_type": action_type,
            "predicted_deltas": predicted_deltas,
            "actual_deltas": actual_deltas,
            "ml_confidence": ml_confidence,
            "used_tier": used_tier,
            "errors": errors
        }

        self.error_history.append(record)

        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä
        if len(self.error_history) > self.max_history:
            self.error_history = self.error_history[-self.max_history:]

    def get_error_metrics(self, action_type: Optional[str] = None) -> Dict:
        """
        –í—ã—á–∏—Å–ª—è–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –æ—à–∏–±–æ–∫.

        Args:
            action_type: –§–∏–ª—å—Ç—Ä –ø–æ action type (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏
        """
        # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ action_type –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω
        records = self.error_history
        if action_type:
            records = [r for r in records if r["action_type"] == action_type]

        if not records:
            return {
                "total_forecasts": 0,
                "action_type": action_type,
                "mean_absolute_error": None,
                "root_mean_squared_error": None,
                "direction_accuracy": None
            }

        # –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
        mae_sum = 0.0
        mse_sum = 0.0
        direction_correct = 0
        total_dims = 0

        for record in records:
            for dim_errors in record["errors"].values():
                mae_sum += dim_errors["absolute_error"]
                mse_sum += dim_errors["squared_error"]
                if dim_errors["direction_correct"]:
                    direction_correct += 1
                total_dims += 1

        n = total_dims
        return {
            "total_forecasts": len(records),
            "action_type": action_type or "all",
            "mean_absolute_error": mae_sum / n if n > 0 else None,
            "root_mean_squared_error": (mse_sum / n) ** 0.5 if n > 0 else None,
            "direction_accuracy": direction_correct / n if n > 0 else None
        }

    def should_retrain(self) -> Tuple[bool, str]:
        """
        –†–µ—à–∏—Ç—å –Ω—É–∂–Ω–æ –ª–∏ –ø–µ—Ä–µ–æ–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å.

        Criteria:
        1. –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö ‚Üí –Ω–µ—Ç
        2. MAE > threshold ‚Üí –¥–∞
        3. Direction accuracy < threshold ‚Üí –¥–∞

        Returns:
            (should_retrain, reason)
        """
        # –ú–∏–Ω–∏–º—É–º –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ä–µ—à–µ–Ω–∏—è
        if len(self.error_history) < 20:
            return False, "Insufficient forecast history"

        metrics = self.get_error_metrics()

        # –ü–æ—Ä–æ–≥–∏
        MAX_MAE = 0.15  # –°—Ä–µ–¥–Ω—è—è –æ—à–∏–±–∫–∞ –Ω–µ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –±–æ–ª—å—à–µ 0.15
        MIN_DIRECTION_ACCURACY = 0.6  # –î–æ–ª–∂–Ω—ã –±—ã—Ç—å –ø—Ä–∞–≤—ã –≤ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–∏ –≤ 60% —Å–ª—É—á–∞–µ–≤

        mae = metrics.get("mean_absolute_error", 0.0)
        direction_acc = metrics.get("direction_accuracy", 1.0)

        if mae > MAX_MAE:
            return True, f"High MAE: {mae:.4f} > {MAX_MAE}"

        if direction_acc < MIN_DIRECTION_ACCURACY:
            return True, f"Low direction accuracy: {direction_acc:.2%} < {MIN_DIRECTION_ACCURACY:.2%}"

        return False, "Model performing adequately"


# =============================================================================
# GLOBAL INSTANCES
# =============================================================================

training_quality_gates = TrainingQualityGates()
per_action_confidence = PerActionConfidence()
drift_detector = DriftDetector()
forecast_error_tracker = ForecastErrorTracker()
